{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on: \n",
    "# https://towardsdatascience.com/deep-learning-using-transfer-learning-python-code-for-resnet50-8acdfb3a2d38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jan/anaconda3/envs/tf-gpu-clone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jan/anaconda3/envs/tf-gpu-clone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jan/anaconda3/envs/tf-gpu-clone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jan/anaconda3/envs/tf-gpu-clone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jan/anaconda3/envs/tf-gpu-clone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jan/anaconda3/envs/tf-gpu-clone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import random\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, plot_confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D#, GlobalAveragePooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "#from keras.layers.core import GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.283123016357422\n",
      "shape training dataset: (2803, 220, 220, 3)\n",
      "shape validation dataset: (467, 220, 220, 3)\n",
      "shape test dataset: (468, 220, 220, 3)\n"
     ]
    }
   ],
   "source": [
    "# This block is used to load the data into RAM\n",
    "\n",
    "# list of dirs containing the data - one for the porosity labeled data and one for the no_porosity_labeled data\n",
    "dirs = ['/media/jan/Volume_big/datasets/Square_data_Gridsize_220_100µm_corrected/3layer/generated_ds/standard/porosity',\n",
    "        '/media/jan/Volume_big/datasets/Square_data_Gridsize_220_100µm_corrected/3layer/generated_ds/standard/no_porosity']\n",
    "\n",
    "length = 1869 # number of samples per category \n",
    "random_seed = 22 \n",
    "image_paths = []\n",
    "show_time = True  # can be toggled to show the time for loading the data into RAM \n",
    "\n",
    "if show_time:\n",
    "    start_time = time.time()\n",
    "\n",
    "# creating a list with paths of all files in each folder     \n",
    "for d in dirs: \n",
    "    cur_paths = []\n",
    "    for path in os.listdir(d):\n",
    "        full_path = os.path.join(d,path)  # adding the full path as the label is stored in the path\n",
    "        cur_paths.append(full_path)\n",
    "    \n",
    "    # randomly shuffling the created list and cutting it to the desired length\n",
    "    # added to the code for being able to deal with non pre-balanced data sets - if folders both have same length nothing happens at this point\n",
    "    random.seed(random_seed) \n",
    "    random.shuffle(cur_paths)\n",
    "    cur_paths = cur_paths[:length] \n",
    "    \n",
    "    image_paths.append(cur_paths) # appending the cut list to a new list containing all the final paths        \n",
    "\n",
    "image_paths = [val for sublist in image_paths for val in sublist] # getting the seperate image paths out of the list\n",
    "random.seed(random_seed)\n",
    "random.shuffle(image_paths) # randomly shuffling the list containing the final paths\n",
    "\n",
    "labels = []\n",
    "data = []\n",
    "# generating the label from the second last part of path for every element in the list and adding it to labels-list\n",
    "# loading the np array, resizing and storing it to data-list\n",
    "\n",
    "for path in image_paths:\n",
    "    label = path.split(os.path.sep)[-2] # here it is 'porosity' or 'no_porosity' \n",
    "    # additionally to the pure label the whole path is stored to make a traceback of model_behaviour possible \n",
    "    # the number needs to be changed according to the link to output something like '/porosity/ZP...'\n",
    "    labels.append([label,path[97:]])\n",
    "    array = np.load(path)\n",
    "    # img = Image.fromarray(array)   # could be added if resizing operation was necessary\n",
    "    # img = img.resize((128, 128), PIL.Image.LANCZOS)\n",
    "    # array_resized = np.array(img)\n",
    "    data.append(array)\n",
    "    \n",
    "# in case of transfer learning the scaling function of the original network should be used \n",
    "data = np.array(data, dtype=\"float\") #/ 255.0 \n",
    "labels = np.array(labels)\n",
    "\n",
    "# splitting data and labels in train, valid and test set in ratio (0.75, 0.125, 0.125)\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "(validX, testX, validY, testY) = train_test_split(testX, testY, test_size=0.5, random_state=42)\n",
    "\n",
    "# at this point the lables are an array with entries like ['porosity', '/porosity/ZP3_Slice00690_x:1_y:1.npy']\n",
    "# the following part splits up the array to generate labels and also a list with the full paths \n",
    "\n",
    "trainY_list = []\n",
    "trainY_path = []\n",
    "testY_list = []\n",
    "testY_path = []\n",
    "validY_list = []\n",
    "validY_path = []\n",
    "\n",
    "for row in trainY:\n",
    "    trainY_list.append(row[0])\n",
    "    trainY_path.append(row[1]) \n",
    "trainY = np.array(trainY_list)\n",
    "trainY_path = np.array(trainY_path)\n",
    "\n",
    "for row in testY:\n",
    "    testY_list.append(row[0])\n",
    "    testY_path.append(row[1]) \n",
    "testY = np.array(testY_list)\n",
    "testY_path = np.array(testY_path)\n",
    "\n",
    "for row in validY:\n",
    "    validY_list.append(row[0])\n",
    "    validY_path.append(row[1]) \n",
    "validY = np.array(validY_list)\n",
    "validY_path = np.array(validY_path)\n",
    "\n",
    "# the LabelBinarizer module is used to one hot encode the labels \n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "validY = lb.transform(validY)\n",
    "\n",
    "# now the Labels are arrays containing either a '0' for 'no_porosity' or a '1' for 'porosity'\n",
    "if show_time:\n",
    "    print(time.time()-start_time)\n",
    "    \n",
    "# the shapes of the different data sets are printed  \n",
    "print('shape training dataset: ' + str(trainX.shape))\n",
    "print('shape validation dataset: ' + str(validX.shape))\n",
    "print('shape test dataset: ' + str(testX.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the inputs with the keras preprocessing function \n",
    "trainX_inception = preprocess_input(trainX)\n",
    "validX_inception = preprocess_input(validX)\n",
    "testX_inception = preprocess_input(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading the model with the imagenet-weights but without the imagenet-classifier \n",
    "inceptionv3 = InceptionV3(include_top = False, weights = 'imagenet', input_shape = (trainX_inception[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f8b0e5bf7f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f8b0e5bfba8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inceptionv3.layers[:2]  # just for tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary with all the layer names\n",
    "layer_name_dict = {}\n",
    "\n",
    "i = 0\n",
    "for layer in inceptionv3.layers:\n",
    "    layer_name_dict[i] = layer\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <keras.engine.input_layer.InputLayer at 0x7f8b0e5bf7f0>,\n",
       " 1: <keras.layers.convolutional.Conv2D at 0x7f8b0e5bfba8>,\n",
       " 2: <keras.layers.normalization.BatchNormalization at 0x7f8b0e5bfac8>,\n",
       " 3: <keras.layers.core.Activation at 0x7f8b34746550>,\n",
       " 4: <keras.layers.convolutional.Conv2D at 0x7f8aac0ade80>,\n",
       " 5: <keras.layers.normalization.BatchNormalization at 0x7f8aac1960b8>,\n",
       " 6: <keras.layers.core.Activation at 0x7f8aa47c09b0>,\n",
       " 7: <keras.layers.convolutional.Conv2D at 0x7f8aa453ae80>,\n",
       " 8: <keras.layers.normalization.BatchNormalization at 0x7f8aa454e940>,\n",
       " 9: <keras.layers.core.Activation at 0x7f8aa4577fd0>,\n",
       " 10: <keras.layers.pooling.MaxPooling2D at 0x7f8aa452c978>,\n",
       " 11: <keras.layers.convolutional.Conv2D at 0x7f8aa452c8d0>,\n",
       " 12: <keras.layers.normalization.BatchNormalization at 0x7f8aa43bad30>,\n",
       " 13: <keras.layers.core.Activation at 0x7f8aa43baf28>,\n",
       " 14: <keras.layers.convolutional.Conv2D at 0x7f8aa43eda90>,\n",
       " 15: <keras.layers.normalization.BatchNormalization at 0x7f8aa438cd68>,\n",
       " 16: <keras.layers.core.Activation at 0x7f8aa4352be0>,\n",
       " 17: <keras.layers.pooling.MaxPooling2D at 0x7f8aa42a0cf8>,\n",
       " 18: <keras.layers.convolutional.Conv2D at 0x7f8a947ab128>,\n",
       " 19: <keras.layers.normalization.BatchNormalization at 0x7f8a9474dac8>,\n",
       " 20: <keras.layers.core.Activation at 0x7f8a946eeba8>,\n",
       " 21: <keras.layers.convolutional.Conv2D at 0x7f8aa41d2be0>,\n",
       " 22: <keras.layers.convolutional.Conv2D at 0x7f8a9463fcc0>,\n",
       " 23: <keras.layers.normalization.BatchNormalization at 0x7f8aa4195898>,\n",
       " 24: <keras.layers.normalization.BatchNormalization at 0x7f8a9465f710>,\n",
       " 25: <keras.layers.core.Activation at 0x7f8aa4162550>,\n",
       " 26: <keras.layers.core.Activation at 0x7f8a94607f28>,\n",
       " 27: <keras.layers.pooling.AveragePooling2D at 0x7f8a944b69e8>,\n",
       " 28: <keras.layers.convolutional.Conv2D at 0x7f8aa42e1908>,\n",
       " 29: <keras.layers.convolutional.Conv2D at 0x7f8aa40eea20>,\n",
       " 30: <keras.layers.convolutional.Conv2D at 0x7f8a94594a20>,\n",
       " 31: <keras.layers.convolutional.Conv2D at 0x7f8a94483e48>,\n",
       " 32: <keras.layers.normalization.BatchNormalization at 0x7f8aa41d2860>,\n",
       " 33: <keras.layers.normalization.BatchNormalization at 0x7f8aa408eba8>,\n",
       " 34: <keras.layers.normalization.BatchNormalization at 0x7f8a9455f748>,\n",
       " 35: <keras.layers.normalization.BatchNormalization at 0x7f8a9441d278>,\n",
       " 36: <keras.layers.core.Activation at 0x7f8aa41f8710>,\n",
       " 37: <keras.layers.core.Activation at 0x7f8aa4058a20>,\n",
       " 38: <keras.layers.core.Activation at 0x7f8a94528208>,\n",
       " 39: <keras.layers.core.Activation at 0x7f8a9441d748>,\n",
       " 40: <keras.layers.merge.Concatenate at 0x7f8a94372c88>,\n",
       " 41: <keras.layers.convolutional.Conv2D at 0x7f8a94047198>,\n",
       " 42: <keras.layers.normalization.BatchNormalization at 0x7f8a9406eb00>,\n",
       " 43: <keras.layers.core.Activation at 0x7f8a50753a90>,\n",
       " 44: <keras.layers.convolutional.Conv2D at 0x7f8a9424a5f8>,\n",
       " 45: <keras.layers.convolutional.Conv2D at 0x7f8a506c6cf8>,\n",
       " 46: <keras.layers.normalization.BatchNormalization at 0x7f8a94273780>,\n",
       " 47: <keras.layers.normalization.BatchNormalization at 0x7f8a5072df28>,\n",
       " 48: <keras.layers.core.Activation at 0x7f8a941bc438>,\n",
       " 49: <keras.layers.core.Activation at 0x7f8a506f3eb8>,\n",
       " 50: <keras.layers.pooling.AveragePooling2D at 0x7f8a5051d8d0>,\n",
       " 51: <keras.layers.convolutional.Conv2D at 0x7f8a94357f60>,\n",
       " 52: <keras.layers.convolutional.Conv2D at 0x7f8a9414b908>,\n",
       " 53: <keras.layers.convolutional.Conv2D at 0x7f8a5067c908>,\n",
       " 54: <keras.layers.convolutional.Conv2D at 0x7f8a5056cd30>,\n",
       " 55: <keras.layers.normalization.BatchNormalization at 0x7f8a9427dcf8>,\n",
       " 56: <keras.layers.normalization.BatchNormalization at 0x7f8a940d3c18>,\n",
       " 57: <keras.layers.normalization.BatchNormalization at 0x7f8a505c5630>,\n",
       " 58: <keras.layers.normalization.BatchNormalization at 0x7f8a50489710>,\n",
       " 59: <keras.layers.core.Activation at 0x7f8a942d8ba8>,\n",
       " 60: <keras.layers.core.Activation at 0x7f8a9416a240>,\n",
       " 61: <keras.layers.core.Activation at 0x7f8a505a8ba8>,\n",
       " 62: <keras.layers.core.Activation at 0x7f8a50468cc0>,\n",
       " 63: <keras.layers.merge.Concatenate at 0x7f8a503dadd8>,\n",
       " 64: <keras.layers.convolutional.Conv2D at 0x7f8a50133ac8>,\n",
       " 65: <keras.layers.normalization.BatchNormalization at 0x7f8a500d5da0>,\n",
       " 66: <keras.layers.core.Activation at 0x7f8a5007ac88>,\n",
       " 67: <keras.layers.convolutional.Conv2D at 0x7f8a503344e0>,\n",
       " 68: <keras.layers.convolutional.Conv2D at 0x7f8a207aaf28>,\n",
       " 69: <keras.layers.normalization.BatchNormalization at 0x7f8a502d9668>,\n",
       " 70: <keras.layers.normalization.BatchNormalization at 0x7f8a2078ee48>,\n",
       " 71: <keras.layers.core.Activation at 0x7f8a502a4390>,\n",
       " 72: <keras.layers.core.Activation at 0x7f8a20754208>,\n",
       " 73: <keras.layers.pooling.AveragePooling2D at 0x7f8a205807b8>,\n",
       " 74: <keras.layers.convolutional.Conv2D at 0x7f8a503bde48>,\n",
       " 75: <keras.layers.convolutional.Conv2D at 0x7f8a502347f0>,\n",
       " 76: <keras.layers.convolutional.Conv2D at 0x7f8a206e37f0>,\n",
       " 77: <keras.layers.convolutional.Conv2D at 0x7f8a205dbc18>,\n",
       " 78: <keras.layers.normalization.BatchNormalization at 0x7f8a50365be0>,\n",
       " 79: <keras.layers.normalization.BatchNormalization at 0x7f8a501d7978>,\n",
       " 80: <keras.layers.normalization.BatchNormalization at 0x7f8a206a6518>,\n",
       " 81: <keras.layers.normalization.BatchNormalization at 0x7f8a205726d8>,\n",
       " 82: <keras.layers.core.Activation at 0x7f8a5033ea90>,\n",
       " 83: <keras.layers.core.Activation at 0x7f8a500ff9b0>,\n",
       " 84: <keras.layers.core.Activation at 0x7f8a2060af98>,\n",
       " 85: <keras.layers.core.Activation at 0x7f8a204cbf28>,\n",
       " 86: <keras.layers.merge.Concatenate at 0x7f8a2047bc18>,\n",
       " 87: <keras.layers.convolutional.Conv2D at 0x7f8a203a43c8>,\n",
       " 88: <keras.layers.normalization.BatchNormalization at 0x7f8a2033a550>,\n",
       " 89: <keras.layers.core.Activation at 0x7f8a203062e8>,\n",
       " 90: <keras.layers.convolutional.Conv2D at 0x7f8a202ec7f0>,\n",
       " 91: <keras.layers.normalization.BatchNormalization at 0x7f8a2023c860>,\n",
       " 92: <keras.layers.core.Activation at 0x7f8a20256ef0>,\n",
       " 93: <keras.layers.convolutional.Conv2D at 0x7f8a2047bcf8>,\n",
       " 94: <keras.layers.convolutional.Conv2D at 0x7f8a201e1a58>,\n",
       " 95: <keras.layers.normalization.BatchNormalization at 0x7f8a20463a58>,\n",
       " 96: <keras.layers.normalization.BatchNormalization at 0x7f8a201b4c88>,\n",
       " 97: <keras.layers.core.Activation at 0x7f8a203c8be0>,\n",
       " 98: <keras.layers.core.Activation at 0x7f8a200fa358>,\n",
       " 99: <keras.layers.pooling.MaxPooling2D at 0x7f8a2004ff28>,\n",
       " 100: <keras.layers.merge.Concatenate at 0x7f8a20090630>,\n",
       " 101: <keras.layers.convolutional.Conv2D at 0x7f8a18458710>,\n",
       " 102: <keras.layers.normalization.BatchNormalization at 0x7f8a1841d438>,\n",
       " 103: <keras.layers.core.Activation at 0x7f8a18384e80>,\n",
       " 104: <keras.layers.convolutional.Conv2D at 0x7f8a183522e8>,\n",
       " 105: <keras.layers.normalization.BatchNormalization at 0x7f8a1831f748>,\n",
       " 106: <keras.layers.core.Activation at 0x7f8a182e9208>,\n",
       " 107: <keras.layers.convolutional.Conv2D at 0x7f8a1876c5c0>,\n",
       " 108: <keras.layers.convolutional.Conv2D at 0x7f8a181fa9e8>,\n",
       " 109: <keras.layers.normalization.BatchNormalization at 0x7f8a1870b898>,\n",
       " 110: <keras.layers.normalization.BatchNormalization at 0x7f8a1821bb70>,\n",
       " 111: <keras.layers.core.Activation at 0x7f8a186d9550>,\n",
       " 112: <keras.layers.core.Activation at 0x7f8a181e36d8>,\n",
       " 113: <keras.layers.convolutional.Conv2D at 0x7f8a18665a20>,\n",
       " 114: <keras.layers.convolutional.Conv2D at 0x7f8a181750f0>,\n",
       " 115: <keras.layers.normalization.BatchNormalization at 0x7f8a18609ba8>,\n",
       " 116: <keras.layers.normalization.BatchNormalization at 0x7f8a18118a90>,\n",
       " 117: <keras.layers.core.Activation at 0x7f8a185d2710>,\n",
       " 118: <keras.layers.core.Activation at 0x7f8a180ddac8>,\n",
       " 119: <keras.layers.pooling.AveragePooling2D at 0x7f89e8720b00>,\n",
       " 120: <keras.layers.convolutional.Conv2D at 0x7f8a20090dd8>,\n",
       " 121: <keras.layers.convolutional.Conv2D at 0x7f8a18565128>,\n",
       " 122: <keras.layers.convolutional.Conv2D at 0x7f89e87d4e80>,\n",
       " 123: <keras.layers.convolutional.Conv2D at 0x7f89e8720668>,\n",
       " 124: <keras.layers.normalization.BatchNormalization at 0x7f8a20076208>,\n",
       " 125: <keras.layers.normalization.BatchNormalization at 0x7f8a18509ac8>,\n",
       " 126: <keras.layers.normalization.BatchNormalization at 0x7f89e87ec9b0>,\n",
       " 127: <keras.layers.normalization.BatchNormalization at 0x7f89e86374e0>,\n",
       " 128: <keras.layers.core.Activation at 0x7f8a18741ba8>,\n",
       " 129: <keras.layers.core.Activation at 0x7f8a184cbb00>,\n",
       " 130: <keras.layers.core.Activation at 0x7f89e87939b0>,\n",
       " 131: <keras.layers.core.Activation at 0x7f89e8615e10>,\n",
       " 132: <keras.layers.merge.Concatenate at 0x7f89e85cbb00>,\n",
       " 133: <keras.layers.convolutional.Conv2D at 0x7f89e81dd0f0>,\n",
       " 134: <keras.layers.normalization.BatchNormalization at 0x7f89e8181a90>,\n",
       " 135: <keras.layers.core.Activation at 0x7f89e8125b70>,\n",
       " 136: <keras.layers.convolutional.Conv2D at 0x7f89e8080c88>,\n",
       " 137: <keras.layers.normalization.BatchNormalization at 0x7f89e809a6d8>,\n",
       " 138: <keras.layers.core.Activation at 0x7f89e8041e10>,\n",
       " 139: <keras.layers.convolutional.Conv2D at 0x7f89e84c5390>,\n",
       " 140: <keras.layers.convolutional.Conv2D at 0x7f88081869e8>,\n",
       " 141: <keras.layers.normalization.BatchNormalization at 0x7f89e8482438>,\n",
       " 142: <keras.layers.normalization.BatchNormalization at 0x7f8808151710>,\n",
       " 143: <keras.layers.core.Activation at 0x7f89e8469e80>,\n",
       " 144: <keras.layers.core.Activation at 0x7f880811a4a8>,\n",
       " 145: <keras.layers.convolutional.Conv2D at 0x7f89e83b92e8>,\n",
       " 146: <keras.layers.convolutional.Conv2D at 0x7f88080aa9b0>,\n",
       " 147: <keras.layers.normalization.BatchNormalization at 0x7f89e8386748>,\n",
       " 148: <keras.layers.normalization.BatchNormalization at 0x7f880804ab38>,\n",
       " 149: <keras.layers.core.Activation at 0x7f89e8353208>,\n",
       " 150: <keras.layers.core.Activation at 0x7f87e2f46f98>,\n",
       " 151: <keras.layers.pooling.AveragePooling2D at 0x7f87e2e1be10>,\n",
       " 152: <keras.layers.convolutional.Conv2D at 0x7f89e85cbbe0>,\n",
       " 153: <keras.layers.convolutional.Conv2D at 0x7f89e82e19e8>,\n",
       " 154: <keras.layers.convolutional.Conv2D at 0x7f87e2f7bc88>,\n",
       " 155: <keras.layers.convolutional.Conv2D at 0x7f87e2e6b4e0>,\n",
       " 156: <keras.layers.normalization.BatchNormalization at 0x7f89e85b0c50>,\n",
       " 157: <keras.layers.normalization.BatchNormalization at 0x7f89e8281b70>,\n",
       " 158: <keras.layers.normalization.BatchNormalization at 0x7f87e2f1eba8>,\n",
       " 159: <keras.layers.normalization.BatchNormalization at 0x7f87e2d45e10>,\n",
       " 160: <keras.layers.core.Activation at 0x7f89e8512a58>,\n",
       " 161: <keras.layers.core.Activation at 0x7f89e8247898>,\n",
       " 162: <keras.layers.core.Activation at 0x7f87e2ee1320>,\n",
       " 163: <keras.layers.core.Activation at 0x7f87e2d8a128>,\n",
       " 164: <keras.layers.merge.Concatenate at 0x7f87e2d0f7f0>,\n",
       " 165: <keras.layers.convolutional.Conv2D at 0x7f87e29269e8>,\n",
       " 166: <keras.layers.normalization.BatchNormalization at 0x7f87e28c7b70>,\n",
       " 167: <keras.layers.core.Activation at 0x7f87e2870dd8>,\n",
       " 168: <keras.layers.convolutional.Conv2D at 0x7f87e2828b00>,\n",
       " 169: <keras.layers.normalization.BatchNormalization at 0x7f87e27caa58>,\n",
       " 170: <keras.layers.core.Activation at 0x7f87e27959e8>,\n",
       " 171: <keras.layers.convolutional.Conv2D at 0x7f87e2c0c2b0>,\n",
       " 172: <keras.layers.convolutional.Conv2D at 0x7f87e26c4c88>,\n",
       " 173: <keras.layers.normalization.BatchNormalization at 0x7f87e2c33ac8>,\n",
       " 174: <keras.layers.normalization.BatchNormalization at 0x7f87e26de6d8>,\n",
       " 175: <keras.layers.core.Activation at 0x7f87e2b5ab70>,\n",
       " 176: <keras.layers.core.Activation at 0x7f87e2684438>,\n",
       " 177: <keras.layers.convolutional.Conv2D at 0x7f87e2b2dcc0>,\n",
       " 178: <keras.layers.convolutional.Conv2D at 0x7f87e2795b00>,\n",
       " 179: <keras.layers.normalization.BatchNormalization at 0x7f87e2acc710>,\n",
       " 180: <keras.layers.normalization.BatchNormalization at 0x7f87e25e3f98>,\n",
       " 181: <keras.layers.core.Activation at 0x7f87e2af3a90>,\n",
       " 182: <keras.layers.core.Activation at 0x7f87e25ac400>,\n",
       " 183: <keras.layers.pooling.AveragePooling2D at 0x7f87e243ac88>,\n",
       " 184: <keras.layers.convolutional.Conv2D at 0x7f87e2d6a630>,\n",
       " 185: <keras.layers.convolutional.Conv2D at 0x7f87e2a02a20>,\n",
       " 186: <keras.layers.convolutional.Conv2D at 0x7f87e253c9b0>,\n",
       " 187: <keras.layers.convolutional.Conv2D at 0x7f87e243ac18>,\n",
       " 188: <keras.layers.normalization.BatchNormalization at 0x7f87e2c802b0>,\n",
       " 189: <keras.layers.normalization.BatchNormalization at 0x7f87e29cf748>,\n",
       " 190: <keras.layers.normalization.BatchNormalization at 0x7f87e24ddb38>,\n",
       " 191: <keras.layers.normalization.BatchNormalization at 0x7f87e239f320>,\n",
       " 192: <keras.layers.core.Activation at 0x7f87e2c5beb8>,\n",
       " 193: <keras.layers.core.Activation at 0x7f87e2999400>,\n",
       " 194: <keras.layers.core.Activation at 0x7f87e2402f98>,\n",
       " 195: <keras.layers.core.Activation at 0x7f87e235a9e8>,\n",
       " 196: <keras.layers.merge.Concatenate at 0x7f87e22dd3c8>,\n",
       " 197: <keras.layers.convolutional.Conv2D at 0x7f87e1f3da20>,\n",
       " 198: <keras.layers.normalization.BatchNormalization at 0x7f87e1e8a748>,\n",
       " 199: <keras.layers.core.Activation at 0x7f87e1e54400>,\n",
       " 200: <keras.layers.convolutional.Conv2D at 0x7f87e1de58d0>,\n",
       " 201: <keras.layers.normalization.BatchNormalization at 0x7f87e1d86a58>,\n",
       " 202: <keras.layers.core.Activation at 0x7f87e1d2feb8>,\n",
       " 203: <keras.layers.convolutional.Conv2D at 0x7f87e2227cc0>,\n",
       " 204: <keras.layers.convolutional.Conv2D at 0x7f87e1ce3ba8>,\n",
       " 205: <keras.layers.normalization.BatchNormalization at 0x7f87e21f0ba8>,\n",
       " 206: <keras.layers.normalization.BatchNormalization at 0x7f87e1c89a58>,\n",
       " 207: <keras.layers.core.Activation at 0x7f87e2119e10>,\n",
       " 208: <keras.layers.core.Activation at 0x7f87e1c4bba8>,\n",
       " 209: <keras.layers.convolutional.Conv2D at 0x7f87e20d0b38>,\n",
       " 210: <keras.layers.convolutional.Conv2D at 0x7f87e1be6e80>,\n",
       " 211: <keras.layers.normalization.BatchNormalization at 0x7f87e20f3b00>,\n",
       " 212: <keras.layers.normalization.BatchNormalization at 0x7f87e1b9e6a0>,\n",
       " 213: <keras.layers.core.Activation at 0x7f87e20b7be0>,\n",
       " 214: <keras.layers.core.Activation at 0x7f87e1b43588>,\n",
       " 215: <keras.layers.pooling.AveragePooling2D at 0x7f87e19e2908>,\n",
       " 216: <keras.layers.convolutional.Conv2D at 0x7f87e232b5f8>,\n",
       " 217: <keras.layers.convolutional.Conv2D at 0x7f87e1ff0cc0>,\n",
       " 218: <keras.layers.convolutional.Conv2D at 0x7f87e1acc940>,\n",
       " 219: <keras.layers.convolutional.Conv2D at 0x7f87e1a32d68>,\n",
       " 220: <keras.layers.normalization.BatchNormalization at 0x7f87e2242128>,\n",
       " 221: <keras.layers.normalization.BatchNormalization at 0x7f87e1f8a6d8>,\n",
       " 222: <keras.layers.normalization.BatchNormalization at 0x7f87e1a8f668>,\n",
       " 223: <keras.layers.normalization.BatchNormalization at 0x7f87e194d748>,\n",
       " 224: <keras.layers.core.Activation at 0x7f87e2205f98>,\n",
       " 225: <keras.layers.core.Activation at 0x7f87e1fb0438>,\n",
       " 226: <keras.layers.core.Activation at 0x7f87e1a49390>,\n",
       " 227: <keras.layers.core.Activation at 0x7f87e192dcf8>,\n",
       " 228: <keras.layers.merge.Concatenate at 0x7f87e189bdd8>,\n",
       " 229: <keras.layers.convolutional.Conv2D at 0x7f87e16f7940>,\n",
       " 230: <keras.layers.normalization.BatchNormalization at 0x7f87e1698ac8>,\n",
       " 231: <keras.layers.core.Activation at 0x7f87e16647f0>,\n",
       " 232: <keras.layers.convolutional.Conv2D at 0x7f87e15bff28>,\n",
       " 233: <keras.layers.normalization.BatchNormalization at 0x7f87e1599dd8>,\n",
       " 234: <keras.layers.core.Activation at 0x7f87e15610b8>,\n",
       " 235: <keras.layers.convolutional.Conv2D at 0x7f87e1882e80>,\n",
       " 236: <keras.layers.convolutional.Conv2D at 0x7f87e14aed68>,\n",
       " 237: <keras.layers.normalization.BatchNormalization at 0x7f87e1847780>,\n",
       " 238: <keras.layers.normalization.BatchNormalization at 0x7f87e1495f60>,\n",
       " 239: <keras.layers.core.Activation at 0x7f87e1829d30>,\n",
       " 240: <keras.layers.core.Activation at 0x7f87e1455358>,\n",
       " 241: <keras.layers.convolutional.Conv2D at 0x7f87e17fa518>,\n",
       " 242: <keras.layers.convolutional.Conv2D at 0x7f87e13e4940>,\n",
       " 243: <keras.layers.normalization.BatchNormalization at 0x7f87e179f6a0>,\n",
       " 244: <keras.layers.normalization.BatchNormalization at 0x7f87e13b0668>,\n",
       " 245: <keras.layers.core.Activation at 0x7f87e1769438>,\n",
       " 246: <keras.layers.core.Activation at 0x7f87e137a400>,\n",
       " 247: <keras.layers.pooling.MaxPooling2D at 0x7f87e1287908>,\n",
       " 248: <keras.layers.merge.Concatenate at 0x7f87e12d9d68>,\n",
       " 249: <keras.layers.convolutional.Conv2D at 0x7f87e0edaf28>,\n",
       " 250: <keras.layers.normalization.BatchNormalization at 0x7f87e0ddbf28>,\n",
       " 251: <keras.layers.core.Activation at 0x7f87e0dff358>,\n",
       " 252: <keras.layers.convolutional.Conv2D at 0x7f87e118a2b0>,\n",
       " 253: <keras.layers.convolutional.Conv2D at 0x7f87e0d51cc0>,\n",
       " 254: <keras.layers.normalization.BatchNormalization at 0x7f87e11467b8>,\n",
       " 255: <keras.layers.normalization.BatchNormalization at 0x7f87e0db3f28>,\n",
       " 256: <keras.layers.core.Activation at 0x7f87e10d5dd8>,\n",
       " 257: <keras.layers.core.Activation at 0x7f87e0d7cdd8>,\n",
       " 258: <keras.layers.convolutional.Conv2D at 0x7f87e10f97f0>,\n",
       " 259: <keras.layers.convolutional.Conv2D at 0x7f87e0f92828>,\n",
       " 260: <keras.layers.convolutional.Conv2D at 0x7f87e0c878d0>,\n",
       " 261: <keras.layers.convolutional.Conv2D at 0x7f87e0baa898>,\n",
       " 262: <keras.layers.pooling.AveragePooling2D at 0x7f87e0aa9fd0>,\n",
       " 263: <keras.layers.convolutional.Conv2D at 0x7f87e12aea90>,\n",
       " 264: <keras.layers.normalization.BatchNormalization at 0x7f87e10bb588>,\n",
       " 265: <keras.layers.normalization.BatchNormalization at 0x7f87e0fb49b0>,\n",
       " 266: <keras.layers.normalization.BatchNormalization at 0x7f87e0c4d5f8>,\n",
       " 267: <keras.layers.normalization.BatchNormalization at 0x7f87e0b4ca20>,\n",
       " 268: <keras.layers.convolutional.Conv2D at 0x7f87e0a4c0b8>,\n",
       " 269: <keras.layers.normalization.BatchNormalization at 0x7f87e11d77b8>,\n",
       " 270: <keras.layers.core.Activation at 0x7f87e101cf98>,\n",
       " 271: <keras.layers.core.Activation at 0x7f87e0f03048>,\n",
       " 272: <keras.layers.core.Activation at 0x7f87e0c30b70>,\n",
       " 273: <keras.layers.core.Activation at 0x7f87e0b1b6d8>,\n",
       " 274: <keras.layers.normalization.BatchNormalization at 0x7f87e09f2fd0>,\n",
       " 275: <keras.layers.core.Activation at 0x7f87e11d7ef0>,\n",
       " 276: <keras.layers.merge.Concatenate at 0x7f87e0e8eb00>,\n",
       " 277: <keras.layers.merge.Concatenate at 0x7f87e0af3e80>,\n",
       " 278: <keras.layers.core.Activation at 0x7f87e09f2f98>,\n",
       " 279: <keras.layers.merge.Concatenate at 0x7f87e094f358>,\n",
       " 280: <keras.layers.convolutional.Conv2D at 0x7f87e05b1cf8>,\n",
       " 281: <keras.layers.normalization.BatchNormalization at 0x7f87e04e2f98>,\n",
       " 282: <keras.layers.core.Activation at 0x7f87e04ca278>,\n",
       " 283: <keras.layers.convolutional.Conv2D at 0x7f87e08429b0>,\n",
       " 284: <keras.layers.convolutional.Conv2D at 0x7f87e045b908>,\n",
       " 285: <keras.layers.normalization.BatchNormalization at 0x7f87e0868b38>,\n",
       " 286: <keras.layers.normalization.BatchNormalization at 0x7f87e03ffa90>,\n",
       " 287: <keras.layers.core.Activation at 0x7f87e082e7f0>,\n",
       " 288: <keras.layers.core.Activation at 0x7f87e03a7ef0>,\n",
       " 289: <keras.layers.convolutional.Conv2D at 0x7f87e078bf98>,\n",
       " 290: <keras.layers.convolutional.Conv2D at 0x7f87e0662c50>,\n",
       " 291: <keras.layers.convolutional.Conv2D at 0x7f87e035cbe0>,\n",
       " 292: <keras.layers.convolutional.Conv2D at 0x7f87e027acc0>,\n",
       " 293: <keras.layers.pooling.AveragePooling2D at 0x7f87e014ad68>,\n",
       " 294: <keras.layers.convolutional.Conv2D at 0x7f87e09a64e0>,\n",
       " 295: <keras.layers.normalization.BatchNormalization at 0x7f87e0764a20>,\n",
       " 296: <keras.layers.normalization.BatchNormalization at 0x7f87e067b6a0>,\n",
       " 297: <keras.layers.normalization.BatchNormalization at 0x7f87e02ffb00>,\n",
       " 298: <keras.layers.normalization.BatchNormalization at 0x7f87e0214710>,\n",
       " 299: <keras.layers.convolutional.Conv2D at 0x7f87e0117668>,\n",
       " 300: <keras.layers.normalization.BatchNormalization at 0x7f87e09392b0>,\n",
       " 301: <keras.layers.core.Activation at 0x7f87e0730a90>,\n",
       " 302: <keras.layers.core.Activation at 0x7f87e058fe80>,\n",
       " 303: <keras.layers.core.Activation at 0x7f87e02c3048>,\n",
       " 304: <keras.layers.core.Activation at 0x7f87e01a4fd0>,\n",
       " 305: <keras.layers.normalization.BatchNormalization at 0x7f87e00e1438>,\n",
       " 306: <keras.layers.core.Activation at 0x7f87e09392e8>,\n",
       " 307: <keras.layers.merge.Concatenate at 0x7f87e05b1828>,\n",
       " 308: <keras.layers.merge.Concatenate at 0x7f87e014a898>,\n",
       " 309: <keras.layers.core.Activation at 0x7f87e0040f98>,\n",
       " 310: <keras.layers.merge.Concatenate at 0x7f87e0072ac8>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.merge.Concatenate at 0x7f87e12d9d68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e0edaf28>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e0ddbf28>,\n",
       " <keras.layers.core.Activation at 0x7f87e0dff358>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e118a2b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e0d51cc0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e11467b8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e0db3f28>,\n",
       " <keras.layers.core.Activation at 0x7f87e10d5dd8>,\n",
       " <keras.layers.core.Activation at 0x7f87e0d7cdd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e10f97f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e0f92828>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e0c878d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e0baa898>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f87e0aa9fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e12aea90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e10bb588>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e0fb49b0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e0c4d5f8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e0b4ca20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e0a4c0b8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e11d77b8>,\n",
       " <keras.layers.core.Activation at 0x7f87e101cf98>,\n",
       " <keras.layers.core.Activation at 0x7f87e0f03048>,\n",
       " <keras.layers.core.Activation at 0x7f87e0c30b70>,\n",
       " <keras.layers.core.Activation at 0x7f87e0b1b6d8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e09f2fd0>,\n",
       " <keras.layers.core.Activation at 0x7f87e11d7ef0>,\n",
       " <keras.layers.merge.Concatenate at 0x7f87e0e8eb00>,\n",
       " <keras.layers.merge.Concatenate at 0x7f87e0af3e80>,\n",
       " <keras.layers.core.Activation at 0x7f87e09f2f98>,\n",
       " <keras.layers.merge.Concatenate at 0x7f87e094f358>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e05b1cf8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e04e2f98>,\n",
       " <keras.layers.core.Activation at 0x7f87e04ca278>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e08429b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e045b908>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e0868b38>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e03ffa90>,\n",
       " <keras.layers.core.Activation at 0x7f87e082e7f0>,\n",
       " <keras.layers.core.Activation at 0x7f87e03a7ef0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e078bf98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e0662c50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e035cbe0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e027acc0>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7f87e014ad68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e09a64e0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e0764a20>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e067b6a0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e02ffb00>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e0214710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f87e0117668>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e09392b0>,\n",
       " <keras.layers.core.Activation at 0x7f87e0730a90>,\n",
       " <keras.layers.core.Activation at 0x7f87e058fe80>,\n",
       " <keras.layers.core.Activation at 0x7f87e02c3048>,\n",
       " <keras.layers.core.Activation at 0x7f87e01a4fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f87e00e1438>,\n",
       " <keras.layers.core.Activation at 0x7f87e09392e8>,\n",
       " <keras.layers.merge.Concatenate at 0x7f87e05b1828>,\n",
       " <keras.layers.merge.Concatenate at 0x7f87e014a898>,\n",
       " <keras.layers.core.Activation at 0x7f87e0040f98>,\n",
       " <keras.layers.merge.Concatenate at 0x7f87e0072ac8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# via inceptionv3.summary() all the concatenate-layers were found - in order to set different concat blocks as trainable \n",
    "# concatenate bei 40, 63, 86, 100, 132, 164, 196, 228, 248, 276, 277, 307, 308\n",
    "\n",
    "inceptionv3.layers[248:] # just for try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. setting the whole network as trainable\n",
    "inceptionv3.trainable = True\n",
    "\n",
    "# 2. looping through the layer names and checking whether the layer name is in the selected range\n",
    "for layer in inceptionv3.layers:\n",
    "    # if layer name in range -> layer stays trainable\n",
    "    if layer in inceptionv3.layers[40:]:\n",
    "        layer.trainable = True\n",
    "    # if layer name not in range -> layer is set to not trainable\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# DataFrame is created to give an overview of the layers and trainablility  \n",
    "layers = [(layer, layer.name, layer.trainable) for layer in inceptionv3.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']).tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here the final model is created from the inceptionv3 feature exxtractor and a new classifier\n",
    "\n",
    "output = inceptionv3.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "inceptionv3 = Model(inceptionv3.input, output=output)\n",
    "\n",
    "inceptionv3.summary()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(inceptionv3)\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the number of epochs, the Batchsize, the optimizer and the Data Augmentation steps are defined \n",
    "# Finally the model is compiled \n",
    "\n",
    "EPOCHS = 500\n",
    "BS = 32\n",
    "opt = SGD(lr=0.01, momentum=0.9, decay=0.01, nesterov = True)     #'Adam' # should be the default optimizer with standard setting according to Hands-On-ML\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "aug = ImageDataGenerator(vertical_flip= True,horizontal_flip=True) # data is randomly flipped horizontally as well as vertically to prevent the NN from learning local dependecies aug = ImageDataGenerator(vertical_flip= True,horizontal_flip=True) # data is randomly flipped horizontally as well as vertically to prevent the NN from learning local dependecies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the actual training process is started \n",
    "\n",
    "# first a file is defined where the model_weights are store\n",
    "filepath=\"model_weights/InceptionV3.best.hdf5\"\n",
    "\n",
    "# the checkpoint saved the model weights whenever the validation loss decreases \n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# EarlyStopping is set up to stop training when validation loss isn't decreasing for a number of epochs defindes by the patience parameter\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "# checkpoint and Early stopping are added to the callbacks list \n",
    "callbacks_list = [checkpoint,es]\n",
    "\n",
    "# Thbe model is fit to the training data and validated with the validation data \n",
    "J = model.fit_generator(aug.flow(trainX_inception, trainY, batch_size=BS),validation_data=(validX_inception, validY), steps_per_epoch=len(trainX) // BS,epochs=EPOCHS,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is used for plotting the learning curve\n",
    "\n",
    "N = np.arange(0,11)#EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure\n",
    "plt.plot(N, J.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, J.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, J.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, J.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy InceptionV3\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is used for creating the confusion matrix and the classification report with the calculated metrics\n",
    "\n",
    "# As a first step the models best weights are loaded before making the predicitions on the so far held back test set\n",
    "model.load_weights(\"model_weights/InceptionV3.best.hdf5\")\n",
    "\n",
    "model_predictions = model.predict(testX_inception)\n",
    "model_predictions =(model_predictions>0.5)\n",
    "\n",
    "cm = confusion_matrix(testY, model_predictions)\n",
    "cr = classification_report(testY, model_predictions)\n",
    "\n",
    "\n",
    "#print(model_name)\n",
    "print(cm)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu-clone]",
   "language": "python",
   "name": "conda-env-tf-gpu-clone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
